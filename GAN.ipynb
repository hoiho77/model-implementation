{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GAN 개념 참고 \n",
    "https://ddongwon.tistory.com/124\n",
    "https://velog.io/@a01152a/%EB%85%BC%EB%AC%B8-%EC%9D%BD%EA%B8%B0-%EB%B0%8F-%EA%B5%AC%ED%98%842-GAN\n",
    "\n",
    "\n",
    "- 두개의 모델이 adversarial process를 통해 동작하며 학습 수행 -> generative model을 estimate하는 새로운 프레임워크\n",
    "- 동시에 2가지 모델을 학습 (1) Generative model \"G\" (2) Discriminative model \"D\"\n",
    "- G와 D 모델이 multilayer perceptron 구조를 지니고 있다면, backpropagation을 통한 학습 가능함.\n",
    "\n",
    "[Discriminator]\n",
    "- D는 입력된 이미지가 진짜(1)인지 가짜(0)인지를 구분\n",
    "\n",
    "[Generator]\n",
    "- G는 확률분포 Pg가 실제 data X의 확률분포를 닮도록 만드는 것이 목표.\n",
    "- G는 latent vector z를 입력받아 가짜 data를 생성해내는 기능 수행\n",
    "- G는 최대한 D가 실수를 하도록 하는 것이 목표로, 모델 D가 모델 G가 생성한 데이터와 실 데이터를 구분하지 못하도록하는 것이 목표\n",
    "\n",
    "\n",
    "[이전 모델] 기존의 generative model은 다양한 확률적 계산 이슈가 존재하였기 때문에 좋은 성능을 기대하기 어려웠으며, Markov chains이나 inference network와 같은 복잡한 기능이 필요하다는 문제점이 존재하였음.\n",
    "본 모델은 해당 한계를 보완\n",
    "\n",
    "- loss function \n",
    "![nn](image/loss_function.png)\n",
    "\n",
    "[좌변] 실제 데이터 x에 대하여 log D(x) 값의 기댓값, D의 성능이 좋을 수록 증가\n",
    "\n",
    "[우변] 가짜 데이터 z에 대하여 log(1-D(G(z))) 값의 기댓값, D가 성능이 좋을 수록 증가\n",
    "\n",
    "따라서, D는 V(D, G) 함수를 maximize, G는 V(D, G) 함수를 minimize 하고자 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid() # 0.5를 기준으로 진짜와 가짜를 classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x): # 모델이 학습데이터 x를 입력받아서 forward propagation을 진행시키는 함수\n",
    "        return self.disc(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim): \n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh() # -1~ 1 사이값 출력\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
